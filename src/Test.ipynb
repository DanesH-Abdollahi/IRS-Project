{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment import Environment\n",
    "from Agent import Agent\n",
    "import numpy as np\n",
    "from plot import plot\n",
    "from Display import disp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(num_of_antennas=5, num_of_irs1=5, num_of_irs2=5,\n",
    "                      path_loss_exponent=2, irs1_to_antenna=20,\n",
    "                      irs2_to_antenna=20, irs1_to_irs2=10, transmitted_power=1)\n",
    "\n",
    "U1 = env.CreateUser(distance_to_antenna=40, distance_to_irs1=10, distance_to_irs2=20,\n",
    "                    noise_var=1e-4, los_to_antenna=True, los_to_irs1=True,\n",
    "                    los_to_irs2=True, sinr_threshold=3, penalty=0, allocated_power=1, weight=1)\n",
    "\n",
    "U2 = env.CreateUser(distance_to_antenna=40, distance_to_irs1=20, distance_to_irs2=10,\n",
    "                    noise_var=1e-4, los_to_antenna=True, los_to_irs1=True,\n",
    "                    los_to_irs2=True, sinr_threshold=3, penalty=0, allocated_power=1, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Can't concatenate scalars (use tf.stack instead) [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m     agent\u001b[39m.\u001b[39mnoise \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_of_iterations):\n\u001b[0;32m---> 37\u001b[0m     action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mchoose_action(obs)\n\u001b[1;32m     39\u001b[0m     new_state, reward, sumrate[ep][\u001b[39miter\u001b[39m], SINRs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mStep(action)\n\u001b[1;32m     41\u001b[0m     \u001b[39m# if iter == 0 or iter == num_of_iterations - 1:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39m#     print(\"****************************************************************\")\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39m#     print(\"action: \", np.array(action))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39m#     print(\"SINR: \", SINRs)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39m#     print(\"****************************************************************\")\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/danes/Desktop/IRS-Project/src/Agent.py:106\u001b[0m, in \u001b[0;36mAgent.choose_action\u001b[0;34m(self, observation, evaluate)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m# print(actions)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m power_cliped \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mclip_by_value(actions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_action)\n\u001b[0;32m--> 106\u001b[0m actions \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconcat([actions, power_cliped], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    108\u001b[0m \u001b[39m# power_action = tf.clip_by_value(power_action, 0, 1)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m# actions = tf.concat([actions, power_action], axis=1)\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mreturn\u001b[39;00m actions[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/IRS/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/IRS/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Can't concatenate scalars (use tf.stack instead) [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "num_of_actions = env.M1 + env.M2 + len(env.Users) * env.N + env.num_of_users - 1\n",
    "\n",
    "agent = Agent(num_states=env.num_of_users, bound=1, batch_size=128, max_size=100000,\n",
    "                env=env, n_actions=num_of_actions,\n",
    "                noise=0.02, alpha=0.0002, beta=0.0004, fc1=512, fc2=256)\n",
    "\n",
    "\n",
    "num_of_episodes = 100\n",
    "num_of_iterations = 100\n",
    "\n",
    "score_history = np.zeros((num_of_episodes,))\n",
    "rewards = np.zeros((num_of_episodes, num_of_iterations))\n",
    "sumrate = np.zeros((num_of_episodes, num_of_iterations))\n",
    "U1_SINR = np.zeros((num_of_episodes, num_of_iterations))\n",
    "U2_SINR = np.zeros((num_of_episodes, num_of_iterations))\n",
    "\n",
    "Old_Avg = 0\n",
    "obs = env.State()\n",
    "agent.noise = 0\n",
    "\n",
    "for ep in range(num_of_episodes):\n",
    "    score = 0\n",
    "    obs = env.State()\n",
    "\n",
    "    if ep < num_of_episodes / 4:\n",
    "        agent.noise = 0.40\n",
    "    elif ep < num_of_episodes * 2 / 4:\n",
    "        agent.noise = 0.20\n",
    "    elif ep < num_of_episodes * 3 / 4:\n",
    "        agent.noise = 0.1\n",
    "    elif ep < num_of_episodes * 3 / 4 + 10:\n",
    "        agent.noise = 0.05\n",
    "    else:\n",
    "        agent.noise = 0\n",
    "\n",
    "    for iter in range(num_of_iterations):\n",
    "        action = agent.choose_action(obs)\n",
    "\n",
    "        new_state, reward, sumrate[ep][iter], SINRs = env.Step(action)\n",
    "\n",
    "        # if iter == 0 or iter == num_of_iterations - 1:\n",
    "        #     print(\"****************************************************************\")\n",
    "        #     print(\"action: \", np.array(action))\n",
    "        #     print(\"state: \", obs)\n",
    "        #     print(\"New state: \", new_state)\n",
    "        #     print(\"SINR: \", SINRs)\n",
    "        #     print(\"****************************************************************\")\n",
    "\n",
    "        agent.remember(obs, action, reward, new_state)\n",
    "        agent.learn()\n",
    "        obs = new_state\n",
    "        score += reward\n",
    "        rewards[ep][iter] = reward\n",
    "\n",
    "        U1_SINR[ep][iter] = SINRs[0]\n",
    "        U2_SINR[ep][iter] = SINRs[1]\n",
    "\n",
    "    # agent.learn()\n",
    "    score = score / num_of_iterations\n",
    "    score_history[ep] = score\n",
    "    New_Avg = score_history[:ep + 1].mean()\n",
    "\n",
    "    disp(episod=ep, score=score, score_history=score_history,\n",
    "            New_Avg=New_Avg, Old_Avg=Old_Avg, SINRs=SINRs, sumrate=sumrate[ep][iter])\n",
    "    \n",
    "    ac = np.array(action)\n",
    "    print(f\"Power split factor = {ac[-1 : ][0]: <5.2} | U1 Power = {np.linalg.norm(U1.w) : <5.2} | U2 Power = {np.linalg.norm(U2.w): <5.2}\" )\n",
    "\n",
    "    # obs = env.Reset()\n",
    "    Old_Avg = New_Avg\n",
    "\n",
    "plot(score_history=score_history, sumrate=sumrate,\n",
    "        u1_sinr=U1_SINR, u2_sinr=U2_SINR, mean=False,\n",
    "        title=f\"N = {env.N}, M1 = {env.M1}, M2 = {env.M2}\")\n",
    "\n",
    "# agent.save_models()\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "print(np.diag(np.angle(env.Psi1, deg=True)))\n",
    "print(\"************************************************************************************\")\n",
    "print(np.diag(np.angle(env.Psi2, deg=True)))\n",
    "# np.linalg.norm(env.Users[1].w)\n",
    "# np.angle(env.Users[0].w, deg=True)\n",
    "print(\"************************************************************************************\")\n",
    "print(max(sumrate.reshape(num_of_episodes*num_of_iterations,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.77096597e-02  6.15524347e-01  3.45171366e+00 -1.40334186e-14\n",
      "  0.00000000e+00]\n",
      "************************************************************************************\n",
      "[ 2.11226994  1.16170345  4.19638775 -1.94091082  6.73502281]\n",
      "************************************************************************************\n",
      "8.419825913625557\n"
     ]
    }
   ],
   "source": [
    "print(np.diag(np.angle(env.Psi1, deg=True)))\n",
    "print(\"************************************************************************************\")\n",
    "print(np.diag(np.angle(env.Psi2, deg=True)))\n",
    "# np.linalg.norm(env.Users[1].w)\n",
    "# np.angle(env.Users[0].w, deg=True)\n",
    "print(\"************************************************************************************\")\n",
    "print(max(sumrate.reshape(num_of_episodes*num_of_iterations,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "matrix = np.array([1,2,3])\n",
    "\n",
    "# matrix.__add__(4)\n",
    "# np.append(matrix, 4)\n",
    "# matrix\n",
    "tmp = tf.constant([1,2,3])\n",
    "# tmp[:-1]\n",
    "tmp = tf.clip_by_value(tmp[:-1], 0, 1)\n",
    "tmp = tf.concat(tmp[-1], 0, 2)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472fcbe080c97205d331d95d913c2f4b8e22dbe4463cef562b4b97ec7ce05cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
